{"cells":[{"cell_type":"markdown","source":["# ML Students PySpark"],"metadata":{}},{"cell_type":"markdown","source":["___\n## Introducción\n\nPara la realización de esta tarea se utilizará el [dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip) que contiene las notas y otras características de alumnos en las asignaturas de matemáticas. [Aquí](https://archive.ics.uci.edu/ml/datasets/Student+Performance) se puede obtener una descripción detallada de todos los atributos. Como alternativa, a continuación se puede consultar estos atributos:\n\n1. school - student's school (binary: \"GP\" - Gabriel Pereira or \"MS\" - Mousinho da Silveira)\n2. sex - student's sex (binary: \"F\" - female or \"M\" - male)\n3. age - student's age (numeric: from 15 to 22)\n4. address - student's home address type (binary: \"U\" - urban or \"R\" - rural)\n5. famsize - family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n6. Pstatus - parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n7. Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n8. Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n9. Mjob - mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n10. Fjob - father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n11. reason - reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n12. guardian - student's guardian (nominal: \"mother\", \"father\" or \"other\")\n13. traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n14. studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n15. failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n16. schoolsup - extra educational support (binary: yes or no)\n17. famsup - family educational support (binary: yes or no)\n18. paid - extra paid classes within the course subject (Math or Portuguése) (binary: yes or no)\n19. activities - extra-curricular activities (binary: yes or no)\n20. nursery - attended nursery school (binary: yes or no)\n21. higher - wants to take higher education (binary: yes or no)\n22. internet - Internet access at home (binary: yes or no)\n23. romantic - with a romantic relationship (binary: yes or no)\n24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n25. freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n26. goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n29. health - current health status (numeric: from 1 - very bad to 5 - very good)\n30. absences - number of school absences (numeric: from 0 to 93)\n31. G1 - first period grade (numeric: from 0 to 20)\n32. G2 - second period grade (numeric: from 0 to 20)\n33. G3 - final grade (numeric: from 0 to 20, output target)\n\nLos pasos que se seguirán tienen que ser:\n1. Cargar los datos en un RDD\n2. Seleccionar sólo las columnas numéricas y añadir una nueva columna con un valor 0 si el alumno ha suspendido (G3 < 10) o 1 si ha aprobado (G3 >= 10)\n3. Transformar el RDD en dataframe\n4. Transformar el dataframe para dejarlo listo para hacer la predicción de la nota G3 y clasificación de si aprueba o no\n5. Crear un modelo para predecir la nota G3 y medir la calidad con el conjunto de entrenamiento y el de test\n6. Crear un modelo para clasificar al alumno en aprobado o suspenso y medir la calidad con el conjunto de entrenamiento y el de test\n\nPara la ejecución de la tarea se ha utilizado el **entorno de Databricks con Spark 2.2.1**"],"metadata":{}},{"cell_type":"markdown","source":["___\n## Preparación del entorno: paquetes y variables\n\nLo primero que vamos hacer es **importar todos los paquetes** necesarios y crear el contexto para los data frames (SQLContext)"],"metadata":{}},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n%matplotlib inline\n\nimport re\nfrom pyspark.sql import SQLContext, Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import corr\nfrom pyspark.ml.feature import VectorAssembler, VectorIndexer, StringIndexer, StandardScaler\nfrom pyspark.ml.regression import LinearRegression, LinearRegressionModel\nfrom pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\nfrom pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\nsqlc = SQLContext(sc)"],"metadata":{"collapsed":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["A continuación se crean las **variables** para:\n* La ruta del fichero y el nombre del fichero con las notas de los alumnos de matemáticas\n* El separador de los campos en el fichero\n* El umbral por defecto que se utilizará para saber si dos variables están correladas\n* El nombre y posición de las columnas tipo numérico en el fichero; además del tipo de dato que será en el dataframe\n* Un array con todos elementos del punto anterior para ser iterable. Además se añade la columna objetivo que valdrá 0 si el alumno ha suspendido (G3 < 10) o 1 en caso contrario (G3 >= 10). Las columnas objetivo (G3 y pass) siempre estarán al final de esta lista. De esta forma, se puede saber que columnas se pueden eliminar si están correladas de forma programática.\n\nTambién se crea una función en la que se devuelve una lista con el nombre de las columnas numéricas."],"metadata":{}},{"cell_type":"code","source":["# Ruta y nombre del fichero student y separador por defecto que utiliza. Ademas del umbral de correlacion por defecto\nRUTA_FICHERO = '/FileStore/tables/student_mat-be366.csv'\nSEPARADOR = ';'\nUMBRAL_CORRELACION = 0.80\n\n# Variables numericas del fichero, la que se crea para saber si un alumno aprueba o no y columna feature: \n#    - posicion 0: nombre de la columna en el fichero\n#    - posicion 1: posicion de la columna en el fichero\n#    - posicion 2: tipo para convertir de RDD a dataframe\n#    - posicion 3: True si la columna puede ser nullable. Se utilizara al convertir de RDD a dataframe.\nCOL_AGE = ('age', 2, DoubleType(), True)\nCOL_MEDU = ('Medu', 6, DoubleType(), True)\nCOL_FEDU = ('Fedu', 7, DoubleType(), True)\nCOL_TRAVELTIME = ('traveltime', 12, DoubleType(), True)\nCOL_STUDYTIME = ('studytime', 13, DoubleType(), True)\nCOL_FAILURES = ('failures', 14, DoubleType(), True)\nCOL_FAMREL = ('famrel', 23, DoubleType(), True)\nCOL_FREETIME = ('freetime', 24, DoubleType(), True)\nCOL_GOOUT = ('goout', 25, DoubleType(), True)\nCOL_DALC = ('Dalc', 26, DoubleType(), True)\nCOL_WALC = ('Walc', 27, DoubleType(), True)\nCOL_HEALTH = ('health', 28, DoubleType(), True)\nCOL_ABSENCES = ('absences', 29, DoubleType(), True)\nCOL_G1 = ('G1', 30, DoubleType(), True)\nCOL_G2 = ('G2', 31, DoubleType(), True)\nCOL_G3 = ('G3', 32, DoubleType(), True)\nCOL_PASS = ('pass', None, DoubleType(), True)\nCOL_FEATURES = ('features', None, None, None)\nCOL_PREDICTION = ('prediction', None, None, None)\n\n# Lista que almacena todas las variables numericas listadas arriba (excepto features) para una mejor iterazion.\n# Las ultimas son las variables target\nCOLS_NUMERICAS = (\n    COL_AGE, \n    COL_MEDU, \n    COL_FEDU, \n    COL_TRAVELTIME, \n    COL_STUDYTIME, \n    COL_FAILURES,\n    COL_FAMREL, \n    COL_FREETIME, \n    COL_GOOUT, \n    COL_DALC, \n    COL_WALC, \n    COL_HEALTH, \n    COL_ABSENCES, \n    COL_G1, \n    COL_G2,\n    COL_G3, \n    COL_PASS)\n# De todos las columnas en la lista anterior, esta variable dice cuantas son target empezando desde atras\nNUMERO_COLUMNAS_TARGET_EN_COLS_NUMERICAS = 2\n\n# Obtiene el nombre de las cabeceras y las devuelve como una lista.\n# parametro cols: lista con elementos que contienen el nombre de la columna. Cada elemento tiene que ser una \n# lista donde la posicion 0 es el nombre de la columna.\ndef obtenerNombreCabeceras(cols=COLS_NUMERICAS):\n    \"\"\"\n    Obtiene el nombre de las cabeceras y las devuelve como una lista.\n\n    :param cols: lista con elementos que contienen el nombre de la columna. Cada elemento tiene que ser una \n    lista donde la posicion 0 es el nombre de la columna. Por defecto es la variable COLS_NUMERICAS\n    :return: lista con el nombre de las columnas pasadas por parametro.\n    \"\"\"\n    \n    nombres = list()\n    for col in cols:\n        nombres.append(col[0])\n    return nombres"],"metadata":{"collapsed":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["___\n## Creación del RDD y filtrado columnas numéricas\n\nUna vez que se han definido las variables, ya se puede **crear el RDD**. Para ello:\n* Se carga el fichero\n* Se elimina la cabecera del fichero utilizando filter\n* Utilizando una función map se obtienen las columnas numéricas:\n    * Se divide la línea por ;\n    * Se seleccionan las columnas numéricas\n    * Se eliminan \" ya que algunos campos numéricos empiezan y/o terminan por esta símbolo\n    * Se trasforma en float\n    * Se añade una columna al final que vale 0 si G3 < 10 (suspenso/a) y 1 si G3 >= 10 (aprobado/a)"],"metadata":{"collapsed":true}},{"cell_type":"code","source":["def convertirANumeroFiltrarYAnyadirPass(linea, separador=SEPARADOR, cols=COLS_NUMERICAS, colTarget=COL_G3):\n    \"\"\"\n    Esta funcion:\n        1. Divide la linea en elementos separados por ;\n        2. Filtra por las columnas que se ha pasado por parametro cols\n        3. Elimina \" para no tener problemas al hacer el cast a float\n        4. Convierte a numero los campos que son numericos\n        5. Se crea un nuevo campo al final con el valor float 0 si G3 es menor que 10 y 1 si es mayor o igual que 10\n\n    :param linea: linea del fichero separada por el separador\n    :param separador: separador de los campos que hay en la linea. Por defecto es SEPARADOR\n    :param cols: lista con elementos que contienen el nombre de la columna. Cada elemento tiene que ser una \n    lista donde la posicion 1 es la posicion en la linea. Por defecto es la variable COLS_NUMERICAS\n    :param colTarget: lista donde la posicion 0 es el nombre de la columna target para crear la variable de si ha aprobado\n    o no. Por defecto es la variable COL_G3\n    :return: lista con los valores float de los campos que se han especificado para filtrar (en el orden pasado en cols) mas \n    un elemento al final cuyo valor es 0 si colTarget es menor que 10 y 1 si es mayor o igual\n    \"\"\"\n    \n    lineaSeparada = linea.split(separador)\n    \n    listaFloat = list()\n    for col in cols:\n        if col[1]:\n            listaFloat.append(float(eliminarDobleComas(lineaSeparada[col[1]])))\n    \n    notaFinal = float(eliminarDobleComas(lineaSeparada[colTarget[1]]))\n    if notaFinal < 10:\n        listaFloat.append(float(0))\n    else:\n        listaFloat.append(float(1))\n        \n    return listaFloat\n\ndef eliminarDobleComas(elemento):\n    \"\"\"\n    Elimina cualquier \" que haya en el parametro.\n    \n    :param elemento: string del que se quiere eliminar \"\n    :return: elemento sin ningun \"\n    \"\"\"\n        \n    return re.sub('\"+', '', elemento)"],"metadata":{"collapsed":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Se lee el csv y se elimina la cabecera\nfichero = sc.textFile(RUTA_FICHERO)\ncabeceraFichero = fichero.first()\ndatos = fichero.filter(lambda x: x!=cabeceraFichero)\n\n# Se hace el map para dividir las filas, quedarse con los campos numericos y convertirlos a float, y anyadir si ha pasado o no\ndatosSoloNumerosYPass = datos.map(convertirANumeroFiltrarYAnyadirPass)\ndatosSoloNumerosYPass.take(3)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["___\n## Trasformación RDD a dataframe y estudio de las variables\n\nSe **trasforma el RDD en un dataframe** creando un esquema para tal fin utilizando la variable COLS_NUMERICAS para hacerlo de forma programática:"],"metadata":{}},{"cell_type":"code","source":["# Esquema que se utiliza para convertir de RDD a Dataframe. Para ello utiliza la variable del principio COLS_NUMERICAS:\n# nombre de la columna, tipo en Spark, si es nullable\nesquema = StructType()\nfor col in COLS_NUMERICAS:\n    esquema.add(StructField(col[0], col[2], col[3]))\n    \n# Se convierte el RDD a dataframe\ndataframe = sqlc.createDataFrame(datosSoloNumerosYPass, esquema)\ndataframe.show(3)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Se muestran las características de cada columna ya que si se hace diretamente sobre todo el dataframe la salida no es muy legible:"],"metadata":{}},{"cell_type":"code","source":["# Para que se vea claro en pantalla se imprime columna por columna el describe\nfor nombrecolumna in obtenerNombreCabeceras():\n    print dataframe.select(nombrecolumna).describe().show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["El siguiente paso es ver la **correlación** entre las columnas y luego eliminar las independientes que estén bastante correladas con otras, esto es, superior al 0.80\n\nPara ello se crean dos funciones:\n* Una que recorra el dataframe y obtenga la correlación columna por columna\n* Otra que obtenga el nombre de las columnas independientes que no estén correladas\nDespués, utilizando select se seleccionan las columnas no correladas además de las columnas objetivo (que corresponden a las dos últimas del dataframe):"],"metadata":{}},{"cell_type":"code","source":["def obtenerCorrelacionColumnasDataframe(dataframe, cols=COLS_NUMERICAS):\n    \"\"\"\n    Obtiene la correlación entre todas columnas del dataframe.\n\n    :param dataframe: dataframe del que se quiere obtener la correlación de las columnas. \n    :param cols: lista con las columnas que se quiere obtener la correlación. Cada elemento tiene que ser una \n    lista donde la posicion 0 es el nombre de la columna. Por defecto es la variable COLS_NUMERICAS\n    :return: lista donde cada element es una list con el nombre de la columna 1, nombre columna 2 y correlación \n    \"\"\"\n    \n    longitudCols = len(cols)\n    # lista con las listas nombre columna 1, nombre columna 2, correlación\n    todasNombresCorrelacion = list()\n    numeroactualCols1 = 0\n    \n    # Recorre todas las columnas en cols. Esta sera columna 1\n    for col1 in cols:\n        \n        # Las siguientes columnas seran columna 2 de tal forma que se pueda crear (columna 1, columna 2, correlación)\n        numeroactualCols2 = numeroactualCols1 + 1\n        while numeroactualCols2 < longitudCols:\n            col2 = cols[numeroactualCols2]\n            # Se calcula la correlación entre columna 1 y columna 2\n            correlacion = dataframe.corr(col1[0], col2[0])\n            # Se crea la lista nombre columna 1 - nombre columna 2 - correlación\n            nombresCorrelacion = [col1[0], col2[0], correlacion]\n            todasNombresCorrelacion.append(nombresCorrelacion)\n            numeroactualCols2 += 1\n            \n        numeroactualCols1 += 1\n    return todasNombresCorrelacion\n\ndef obtenerCabecerasNoCorrelacionadas(listaCol1Col2Correlacion, cols=COLS_NUMERICAS, \n                                      colsTarget=COLS_NUMERICAS[-NUMERO_COLUMNAS_TARGET_EN_COLS_NUMERICAS:], \n                                      umbral=UMBRAL_CORRELACION):\n    \"\"\"\n    Obtiene todas las cabeceras cuyas correlación es inferior al umbral.\n\n    :param listaCol1Col2Correlacion: lista cuyos elementos son listas con el formato \n    nombre columna 1, nombre columna 2, correlacion\n    :param cols: lista con las columnas de las correlaciones. Cada elemento tiene que ser una lista donde \n    la posicion 0 es el nombre de la columna. Por defecto es la variable COLS_NUMERICAS.\n    :param colsTarget: lista con las columnas de las correlaciones que son target y no se eliminaran.\n    Cada elemento tiene que ser una lista donde la posicion 0 es el nombre de la columna. \n    Por defecto es la variable COLS_NUMERICAS[-NUMERO_COLUMNAS_TARGET_EN_COLS_NUMERICAS:].\n    :param umbral: umbral que dice si dos columnas estan correlaciondas y por tanto 1 de ellas sera eliminada. Por \n    defecto es UMBRAL_CORRELACION, si es superior a 1 o menor que 0 se pone a valor UMBRAL_CORRELACION\n    :return: lista con el nombre de las columnas que no estan correlacionadas con otras, ademas de las columnas target\n    \"\"\"\n        \n    # Se comprueba que el umbral sea mayor que 0 y menor que 1. Si no se pone el de por defecto\n    if umbral < 0 or umbral > 1:\n        umbral = UMBRAL_CORRELACION\n    \n    # Se obtienen todos los nombres de las columnas. A partir de aqui se iran eliminando las que estan correlacionadas\n    cabeceras = obtenerNombreCabeceras(cols)\n    nombreColsTarget = obtenerNombreCabeceras(colsTarget)\n    \n    # Se recorre la lista con las correlaciones. Si es mayor que el umbral y ninguna de las columnas son \n    # target, se elimina una de ellas\n    for col1Col2Correlacion in listaCol1Col2Correlacion:\n        if col1Col2Correlacion[0] not in nombreColsTarget and col1Col2Correlacion[1] not in nombreColsTarget:\n            if (-umbral >= col1Col2Correlacion[2] or umbral <= col1Col2Correlacion[2]) and col1Col2Correlacion[0] in cabeceras:\n                cabeceras.remove(col1Col2Correlacion[0])\n    return cabeceras"],"metadata":{"collapsed":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":["col1Col2Correlaciones = obtenerCorrelacionColumnasDataframe(dataframe)\nprint 'Correlación entre columnas columna 1 - columna 2 - correlación: {0}'.format(col1Col2Correlaciones)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["cabecerasParaSelect = obtenerCabecerasNoCorrelacionadas(col1Col2Correlaciones)\nprint 'Total cabeceras cuya correlación no es superior al umbral (mas las columnas target): {0}. Estas cabeceras son: {1}'.format(len(cabecerasParaSelect), cabecerasParaSelect)\n\ncabecerasEliminadas = list()\nfor col in obtenerNombreCabeceras():\n    if col not in cabecerasParaSelect:\n        cabecerasEliminadas.append(col)\nprint 'Total cabeceras eliminadas: {0}. Cabeceras eliminadas: {1}'.format(len(cabecerasEliminadas), cabecerasEliminadas)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["dataframeReducido = dataframe.select(cabecerasParaSelect)\ndataframeReducido.show(5)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["___\n## Creación dataframes listos para los modelos\n\nLos dos último pasos antes de crear los modelos son:\n* Añadir las variables independientes en un vector. Después se guardarán en cache los dos conjuntos para que el rendimiento sea mejor.\n* Separar el conjunto entre conjunto de entrenamiento y el de test. La relación será 70/30"],"metadata":{}},{"cell_type":"code","source":["# Antes de crear el VectorAssembler se obtienen el nombre de las columnas de las variables independientes\n# Para ello se coge la lista con las columnas no correladas y se eliminan las target (que seran las ultimas en COLS_NUMERICAS)\ncabecerasVectorAssembler = cabecerasParaSelect[:]\nfor cabeceraTarget in obtenerNombreCabeceras()[-NUMERO_COLUMNAS_TARGET_EN_COLS_NUMERICAS:]:\n    cabecerasVectorAssembler.remove(cabeceraTarget)\n\n# Se crea el VectorAssembler poniendo el resultado en COL_FEATURES[0] columna\nvectorAssembler = VectorAssembler(\n    inputCols=cabecerasVectorAssembler, \n    outputCol=COL_FEATURES[0])\n\ndataframeEnsamblado = vectorAssembler.transform(dataframeReducido)\ndataframeEnsamblado.show(3)\n\ndataframeEnsamblado.cache()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# Se divide el dataframe en entrenamiento y test\ndataframeEnsambladoDividido = dataframeEnsamblado.randomSplit([0.7, 0.3], 1234)\ndataframeEnsambladoEntrenamiento = dataframeEnsambladoDividido[0]\ndataframeEnsambladoTest = dataframeEnsambladoDividido[1]"],"metadata":{"collapsed":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["___\n## Predicción: modelo de regresión \n\nPara la contrucción del modelo de predicción se utiliza una regresión lineal con **cross validation**. Los valores que se le pasará son:\n* regParam: 0.0, 0.01, 0.05, 0.5\n* maxIter: 5, 10\n* numFolds: 5\n\nUna vez conseguido el modelo, se muestra el intercept y los coeficientes del mejor de ellos. Se puede ver el gran peso que tiene G2 en la predicción de G3:"],"metadata":{"collapsed":true}},{"cell_type":"code","source":["# Se crea el evaluador para este modelo siendo la columna objetivo COL_G3[0]\nevaluatorRegression = RegressionEvaluator(labelCol=COL_G3[0])\n\n# Se crea la regresión lineal con solve=normal \nlinearRegression = LinearRegression(solver='normal', labelCol=COL_G3[0], featuresCol=COL_FEATURES[0])\n# Crossvalidation: los parámetros escogidos son:\n#     * regParam: 0.0, 0.01, 0.05, 0.5\n#     * maxIter: 5, 10\n#     * numFolds: 5\ngridLinearRegression = ParamGridBuilder(). \\\n                        addGrid(linearRegression.regParam, [0.0, 0.01, 0.05, 0.5]). \\\n                        addGrid(linearRegression.maxIter, [5, 10]).build()\ncrossValidatorLinearRegression = CrossValidator(estimator=linearRegression, \\\n                                                estimatorParamMaps=gridLinearRegression, \\\n                                                evaluator=evaluatorRegression, \\\n                                                numFolds=5)\n# Se obtiene el modelo con los datos de entrada\ncrossValidatorLinearRegressionModel = crossValidatorLinearRegression.fit(dataframeEnsambladoEntrenamiento)\n\n# Se muestra el intercept y los coeficientes del mejor modelo\nprint 'Intercept del mejor modelo: {0}'.format(crossValidatorLinearRegressionModel.bestModel.intercept)\nprint 'Coeficientes del mejor modelo: {0}'.format(crossValidatorLinearRegressionModel.bestModel.coefficients)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["Se obtiene la predicción para el conjunto de entrenamiento y el de test con el mejor modelo para posteriormente mostrar el **RMSE**:"],"metadata":{}},{"cell_type":"code","source":["# Se obtiene la predicción sobre el conjunto de test y entrenamiento\ndataframeEnsambladoEntrenamientoPrediccion = crossValidatorLinearRegressionModel.bestModel.transform(dataframeEnsambladoEntrenamiento)\ndataframeEnsambladoTestPrediccion = crossValidatorLinearRegressionModel.bestModel.transform(dataframeEnsambladoTest)\n\n# Se obtiene el RMSE sobre los dos conjuntos\nrmseLinearRegressionEntrenamiento = evaluatorRegression.evaluate(dataframeEnsambladoEntrenamientoPrediccion, {evaluatorRegression.metricName: 'rmse'})\nrmseLinearRegressionTest = evaluatorRegression.evaluate(dataframeEnsambladoTestPrediccion, {evaluatorRegression.metricName: 'rmse'})\n# Se imprime por pantalla\nprint 'RMSE en training: {0}'.format(rmseLinearRegressionEntrenamiento)\nprint 'RMSE en test: {0}'.format(rmseLinearRegressionTest)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["Como se puede observer el error en el conjunto de entrenamiento es ligeramente superior al de test. No obstante ninguno supera el valor 2.\n\nA continuación se muestran en un gráfico la nota real frente a la predicha tanto para el conjunto de test como para el de entrenamiento. Como se podrá observar la gran mayoría se están al rededor de la líena azul que sería la perfección. En los que se puede ver una gran diferencia entre lo predicho y lo real es cuando esta última es 0:"],"metadata":{}},{"cell_type":"code","source":["# Se crea la lista con la nota real y la predicha\nxEntrenamiento, yEntrenamiento = list(), list()\nfor entrenamientoPrediccion in dataframeEnsambladoEntrenamientoPrediccion.collect():\n    xEntrenamiento.append(entrenamientoPrediccion[COL_G3[0]])\n    yEntrenamiento.append(entrenamientoPrediccion[COL_PREDICTION[0]])\nxTest, yTest = list(), list()\nfor testPrediccion in dataframeEnsambladoTestPrediccion.collect():\n    xTest.append(testPrediccion[COL_G3[0]])\n    yTest.append(testPrediccion[COL_PREDICTION[0]])\n\n# Se crea el gráfico y se muestra\nplt.clf()\nplt.xlim(0, 20)\nplt.ylim(0, 20)\nplt.xlabel('Nota real')\nplt.ylabel('Nota segun el modelo')\nplt.title('Nota real vs prediccion Regresion lineal conjunto test')\n\nplt.plot([0, 20], [0, 20], 'b')\n# Se pasan los datos de entrenamiento y test al gráfico\nplt.plot(xEntrenamiento, yEntrenamiento, 'go', label='Entrenamiento')\nplt.plot(xTest, yTest, 'ro', label='Test')\nplt.legend(loc='lower right')\n\nplt.show()\ndisplay()\n"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["___\n## Clasificación: árboles de decisión \n\nPara la contrucción del modelo de clasificación se ha obtado por un árbol de decisión con **cross validation**. Los valores que se le pasará son:\n* maxDepth: 3, 6, 10\n* maxBins: 20, 40, 80\n* numFolds: 5\n\nUna vez conseguido el modelo, se muestra el número de nodos, la profundidad y el árbol en sí del mejor de ellos:"],"metadata":{}},{"cell_type":"code","source":["# Se crea el evaluador para este modelo siendo la columna objetivo COL_PASS[0]\nevaluatorBinaryClassification = BinaryClassificationEvaluator(labelCol=COL_PASS[0])\n\n# Se crea el árbol de decisión\ndecisionTreeClassifier = DecisionTreeClassifier(labelCol=COL_PASS[0], featuresCol=COL_FEATURES[0])\n# Crossvalidation: los parámetros escogidos son:\n#     * maxDepth: 3, 6, 10\n#     * maxBins: 20, 40, 80\n#     * numFolds: 5\ngridTreeClassifier = ParamGridBuilder(). \\\n                        addGrid(decisionTreeClassifier.maxDepth, [3, 6, 10]). \\\n                        addGrid(decisionTreeClassifier.maxBins, [20, 40, 80]).build()\ncrossValidatorDecisionTree = CrossValidator(estimator=decisionTreeClassifier, \\\n                                                estimatorParamMaps=gridTreeClassifier, \\\n                                                evaluator=evaluatorBinaryClassification, \\\n                                                numFolds=5)\n# Se obtiene el modelo con los datos de entrada\ncrossValidatorDecisionTreeModel = crossValidatorDecisionTree.fit(dataframeEnsambladoEntrenamiento)\n\n# Se muestra el número de nodos, profundida y el árbol mejor modelo\nprint 'Número del nodos del mejor modelo: {0}'.format(crossValidatorDecisionTreeModel.bestModel.numNodes)\nprint 'Profundidad del mejor modelo: {0}'.format(crossValidatorDecisionTreeModel.bestModel.depth)\nprint 'Árbol mejor modelo: {0}'.format(crossValidatorDecisionTreeModel.bestModel.toDebugString)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Se puede ver que el campo más significativo en este árbol es feature 13 que corresponde a G2. Era de esperar que tuviese mucha importancia porque está muy correlado con la variable dependiente.\n\nA continuación se obtiene la predicción para el conjunto de entrenamiento y el de test con el mejor modelo para posteriormente mostrar el **área bajo la curva ROC**:"],"metadata":{}},{"cell_type":"code","source":["# Se obtiene la predicción sobre el conjunto de test y entrenamiento\ndataframeEnsambladoEntrenamientoClasificacionPrediccion = crossValidatorDecisionTreeModel.bestModel.transform(dataframeEnsambladoEntrenamiento)\ndataframeEnsambladoTestClasificacionPrediccion = crossValidatorDecisionTreeModel.bestModel.transform(dataframeEnsambladoTest)\n\n# Se obtiene el RMSE sobre los dos conjuntos\narearocDecisionTreeEntrenamiento = evaluatorBinaryClassification.evaluate(\\\n                                                                          dataframeEnsambladoEntrenamientoClasificacionPrediccion, \\\n                                                                          {evaluatorBinaryClassification.metricName: 'areaUnderROC'})\narearocDecisionTreeTest = evaluatorBinaryClassification.evaluate(\\\n                                                                 dataframeEnsambladoTestClasificacionPrediccion, \\\n                                                                 {evaluatorBinaryClassification.metricName: 'areaUnderROC'})\n# Se imprime por pantalla\nprint 'Área bajo la curva ROC en training: {0}'.format(arearocDecisionTreeEntrenamiento)\nprint 'Área bajo la curva ROC en test: {0}'.format(arearocDecisionTreeTest)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["Como se puede observar está muy cerca del ideal. Y por último se dibuja la curva ROC. El área bajo la curva no es la misma que la obtenida a través del modelo. Esto puede deberse a que no se está teniendo en cuenta la probabilidad que estima el modelo:"],"metadata":{"collapsed":true}},{"cell_type":"code","source":["# Se crea la lista con la nota real y la predicha\nxEntrenamiento, yEntrenamiento = list(), list()\nfor entrenamientoPrediccion in dataframeEnsambladoEntrenamientoClasificacionPrediccion.collect():\n    xEntrenamiento.append(entrenamientoPrediccion[COL_PASS[0]])\n    yEntrenamiento.append(entrenamientoPrediccion[COL_PREDICTION[0]])\nxTest, yTest = list(), list()\nfor testPrediccion in dataframeEnsambladoTestClasificacionPrediccion.collect():\n    xTest.append(testPrediccion[COL_PASS[0]])\n    yTest.append(testPrediccion[COL_PREDICTION[0]])\n\n# Se obtienen los falsos positivos y verdaderos positivos y el valor bajo la curva para el test y el entrenamiento\nfalsePositiveRateEntrenamiento, truePositiveRateEntrenamiento, thresholdsEntrenamiento = roc_curve(xEntrenamiento, yEntrenamiento)\nrocAucEntrenamiento = auc(falsePositiveRateEntrenamiento, truePositiveRateEntrenamiento)\nfalsePositiveRateTest, truePositiveRateTest, thresholdsTest = roc_curve(xTest, yTest)\nrocAucTest = auc(falsePositiveRateTest, truePositiveRateTest)\n\n# Se crea el gráfico y se muestra\nplt.clf()\nplt.title('Curva ROC con Arbol de decision')\n# Se pasan los datos de entrenamiento y test al gráfico\nplt.plot(falsePositiveRateEntrenamiento, truePositiveRateEntrenamiento, 'g', label='AUC Entrenamiento = %0.2f'% rocAucEntrenamiento)\nplt.plot(falsePositiveRateTest, truePositiveRateTest, 'r', label='AUC Test = %0.2f'% rocAucTest)\nplt.legend(loc='lower right')\nplt.plot([0,1], [0,1], 'r--')\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.ylabel('True Positive Ratio')\nplt.xlabel('False Positive Ratio')\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["___\n## Conclusión\nComo se ha visto, es muy sencillo la carga de datos en RDD/dataframe, modificación de los distintos campos y preparación para los modelos.\n\nA modo de ejemplo, aunque no se ha utilizado en la tarea, se podría escalar todas las columnas en el dataframe de la siguiente manera:\n```python\nscaler = StandardScaler(inputCol=COL_FEATURES[0], outputCol='scaled'+COL_FEATURES[0], withStd=True, withMean=True)\nscalerModel = scaler.fit(dataframeEnsamblado)\nscaledData = scalerModel.transform(dataframeEnsamblado)\nscaledData.select(COL_FEATURES[0], 'scaled'+COL_FEATURES[0]).show(3)```\n\nDespués se pueden crear modelos de predicción y clasificación con distintos algoritmos. Si se quisiese utilizar otro algoritmo, bastaría con cambiar la clase ya que todas tienen la misma interfaz. De hecho, se podría utilizar un bucle con distintos algorimos y quedarnos con el mejor de ellos."],"metadata":{}}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.14","nbconvert_exporter":"python","file_extension":".py"},"name":"ML Students PySpark","notebookId":1240587378362186},"nbformat":4,"nbformat_minor":0}
